{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-19 05:35:18,111 loading file ../flair-custom/resume2/best-model.pt\n",
      "2022-08-19 05:35:20,951 SequenceTagger predicts: Dictionary with 35 tags: O, S-geo, B-geo, E-geo, I-geo, S-tim, B-tim, E-tim, I-tim, S-org, B-org, E-org, I-org, S-per, B-per, E-per, I-per, S-gpe, B-gpe, E-gpe, I-gpe, S-art, B-art, E-art, I-art, S-eve, B-eve, E-eve, I-eve, S-nat, B-nat, E-nat, I-nat, <START>, <STOP>\n",
      "('UNK Washington UNK UNK went UNK UNK State', 'UNK Washington and I went to Washington State', 'UNK UNK UNK I UNK to UNK UNK', 'UNK Washington UNK UNK UNK to UNK State', 'UNK Washington UNK I went to Washington State')\n",
      "WORD TO EXPLAIN Token[6]: \"Washington\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=geo\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.853</b>, score <b>3.079</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +9.810\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.64%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -6.731\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"opacity: 0.80\">George </span><span style=\"background-color: hsl(120, 100.00%, 96.03%); opacity: 0.81\" title=\"0.121\">Washington</span><span style=\"opacity: 0.80\"> and </span><span style=\"background-color: hsl(120, 100.00%, 96.69%); opacity: 0.81\" title=\"0.093\">I</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.93%); opacity: 0.85\" title=\"0.813\">went</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"3.278\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 67.59%); opacity: 0.95\" title=\"2.426\">Washington</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.81%); opacity: 0.83\" title=\"0.531\">State</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=org\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.109</b>, score <b>-1.970</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 97.88%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.398\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.61%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.368\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"opacity: 0.80\">George Washington </span><span style=\"background-color: hsl(120, 100.00%, 90.02%); opacity: 0.83\" title=\"0.451\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.42%); opacity: 0.82\" title=\"-0.363\">I</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.04%); opacity: 0.81\" title=\"0.216\">went</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.89%); opacity: 0.87\" title=\"-1.227\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.85%); opacity: 0.86\" title=\"-1.060\">Washington</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.08%); opacity: 0.82\" title=\"-0.384\">State</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=O\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.019</b>, score <b>-3.804</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.34%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.867\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.40%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.936\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 93.46%); opacity: 0.82\" title=\"-0.246\">George</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.61%); opacity: 0.80\" title=\"0.058\">Washington</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.70%); opacity: 0.81\" title=\"-0.136\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.10%); opacity: 0.80\" title=\"0.077\">I</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.61%); opacity: 0.82\" title=\"-0.352\">went</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.27%); opacity: 0.80\" title=\"0.071\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 76.34%); opacity: 0.89\" title=\"-1.548\">Washington</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.40%); opacity: 0.84\" title=\"0.630\">State</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "Explanation(estimator=\"SGDClassifier(alpha=0.001, loss='log', penalty='elasticnet',\\n              random_state=RandomState(MT19937) at 0x7FA232200E40)\", description=None, error=None, method='linear model', is_regression=False, targets=[TargetExplanation(target='geo', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='[6] Washington', weight=4.852944796322416, std=None, value=1.0), FeatureWeight(feature='[5] to', weight=3.2775661576802277, std=None, value=1.0), FeatureWeight(feature='[4] went', weight=0.8127981869412001, std=None, value=1.0), FeatureWeight(feature='[7] State', weight=0.5313848250374239, std=None, value=1.0), FeatureWeight(feature='[1] Washington', weight=0.24200455804738258, std=None, value=1.0), FeatureWeight(feature='[3] I', weight=0.09318696045549824, std=None, value=1.0)], neg=[FeatureWeight(feature='<BIAS>', weight=-6.7307856047615475, std=None, value=1.0)], pos_remaining=0, neg_remaining=0), proba=0.8526744422194474, score=3.079099879722601, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document='George Washington and I went to Washington State', spans=[('Washington', [(7, 17)], 0.24200455804738258), ('I', [(22, 23)], 0.09318696045549824), ('went', [(24, 28)], 0.8127981869412001), ('to', [(29, 31)], 3.2775661576802277), ('Washington', [(32, 42)], 4.852944796322416), ('State', [(43, 48)], 0.5313848250374239)], preserve_density=False, vec_name=None)], other=FeatureWeights(pos=[FeatureWeight(feature=<FormattedFeatureName 'Highlighted in text (sum)'>, weight=9.809885484484148, std=None, value=None)], neg=[FeatureWeight(feature='<BIAS>', weight=-6.7307856047615475, std=None, value=1.0)], pos_remaining=0, neg_remaining=0)), heatmap=None), TargetExplanation(target='org', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='[2] and', weight=0.4508173267622864, std=None, value=1.0), FeatureWeight(feature='<BIAS>', weight=0.3978428575790612, std=None, value=1.0), FeatureWeight(feature='[4] went', weight=0.21613668765037555, std=None, value=1.0)], neg=[FeatureWeight(feature='[5] to', weight=-1.2272204902456068, std=None, value=1.0), FeatureWeight(feature='[6] Washington', weight=-1.0597309457455695, std=None, value=1.0), FeatureWeight(feature='[7] State', weight=-0.38431238759333547, std=None, value=1.0), FeatureWeight(feature='[3] I', weight=-0.36348361646468397, std=None, value=1.0)], pos_remaining=0, neg_remaining=0), proba=0.10916314091375318, score=-1.9699505680574727, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document='George Washington and I went to Washington State', spans=[('and', [(18, 21)], 0.4508173267622864), ('I', [(22, 23)], -0.36348361646468397), ('went', [(24, 28)], 0.21613668765037555), ('to', [(29, 31)], -1.2272204902456068), ('Washington', [(32, 42)], -1.0597309457455695), ('State', [(43, 48)], -0.38431238759333547)], preserve_density=False, vec_name=None)], other=FeatureWeights(pos=[FeatureWeight(feature='<BIAS>', weight=0.3978428575790612, std=None, value=1.0)], neg=[FeatureWeight(feature=<FormattedFeatureName 'Highlighted in text (sum)'>, weight=-2.367793425636534, std=None, value=None)], pos_remaining=0, neg_remaining=0)), heatmap=None), TargetExplanation(target='O', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='[7] State', weight=0.6296026389865822, std=None, value=1.0), FeatureWeight(feature='[1] Washington', weight=0.11681986352703565, std=None, value=1.0), FeatureWeight(feature='[3] I', weight=0.07705461984284297, std=None, value=1.0), FeatureWeight(feature='[5] to', weight=0.0706674815756288, std=None, value=1.0)], neg=[FeatureWeight(feature='[6] Washington', weight=-3.0961393438077716, std=None, value=1.0), FeatureWeight(feature='<BIAS>', weight=-0.8674517709815235, std=None, value=1.0), FeatureWeight(feature='[4] went', weight=-0.3522809369112303, std=None, value=1.0), FeatureWeight(feature='[0] George', weight=-0.24641459277385194, std=None, value=1.0), FeatureWeight(feature='[2] and', weight=-0.13554766008565647, std=None, value=1.0)], pos_remaining=0, neg_remaining=0), proba=0.019445554173110686, score=-3.803689700627944, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document='George Washington and I went to Washington State', spans=[('George', [(0, 6)], -0.24641459277385194), ('Washington', [(7, 17)], 0.11681986352703565), ('and', [(18, 21)], -0.13554766008565647), ('I', [(22, 23)], 0.07705461984284297), ('went', [(24, 28)], -0.3522809369112303), ('to', [(29, 31)], 0.0706674815756288), ('Washington', [(32, 42)], -3.0961393438077716), ('State', [(43, 48)], 0.6296026389865822)], preserve_density=False, vec_name=None)], other=FeatureWeights(pos=[], neg=[FeatureWeight(feature=<FormattedFeatureName 'Highlighted in text (sum)'>, weight=-2.936237929646421, std=None, value=None), FeatureWeight(feature='<BIAS>', weight=-0.8674517709815235, std=None, value=1.0)], pos_remaining=0, neg_remaining=0)), heatmap=None)], feature_importances=None, decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus, CSVClassificationCorpus\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.data import Sentence\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# This is a local path. The model is too large to add to\n",
    "# the Git repository\n",
    "path = '../flair-custom/resume2/'\n",
    "model = SequenceTagger.load(path + 'best-model.pt')\n",
    "\n",
    "from eli5.lime import TextExplainer\n",
    "from eli5.lime.samplers import MaskingTextSampler\n",
    "\n",
    "text = 'George Washington and I went to Washington State'\n",
    "s = Sentence(text)\n",
    "\n",
    "def predict_one_sentence(text, word_index):\n",
    "    \"\"\"\n",
    "    Inputs: text - string, containing the sentence to analyze.\n",
    "            word_index - integer, the index of the word who's prediction\n",
    "                         you want to explain.\n",
    "\n",
    "    Return: list of probabilities for each possible tag.\n",
    "    \"\"\"\n",
    "    sentence = Sentence(text)\n",
    "    model.predict(sentence, return_probabilities_for_all_classes=True)\n",
    "\n",
    "    w = sentence[word_index].text\n",
    "\n",
    "    tag_probs = {'O': 0, 'geo': 0, 'tim': 0, 'org': 0, 'per': 0, 'gpe': 0, 'art': 0, 'eve': 0, 'nat': 0}\n",
    "\n",
    "    # iterate over tags in sentences (sentences[i])\n",
    "    # in tags, iterate over tags_proba_dist['ner'][j]\n",
    "    for probs in sentence[word_idx].tags_proba_dist['ner']:\n",
    "        tag = probs.data_point\n",
    "\n",
    "        if tag in ['<START>', '<STOP>']:\n",
    "            tag = 'O'\n",
    "        if tag != 'O':\n",
    "           tag = tag[2:]\n",
    "\n",
    "        tag_probs[tag] += probs.value\n",
    "\n",
    "    tag_prob_array = np.zeros((len(tag_probs)))\n",
    "\n",
    "    prob_tot = 0\n",
    "    for i,val in enumerate(tag_probs.values()):\n",
    "        tag_prob_array[i] = val\n",
    "        prob_tot += val\n",
    "\n",
    "    # There is a small delta between 1.0 and\n",
    "    # the sum of all probabilities. It seems to be\n",
    "    # about 1e-8 or so, which could be because\n",
    "    # the internal model is using floats, but\n",
    "    # LIME is using doubles.\n",
    "    tag_prob_array[0] += 1.0 - prob_tot\n",
    "\n",
    "    return tag_prob_array\n",
    "\n",
    "\n",
    "\n",
    "def get_predict_function(word_index):\n",
    "    \"\"\"\n",
    "    Instantiates and returns the predict function needed by the TextExplainer fit function.\n",
    "\n",
    "    We instantiate 'predict_fun' here so that it will get the value of 'word_idx'. \n",
    "    \"\"\"\n",
    "    def predict_func(texts):\n",
    "\n",
    "        out = np.zeros((len(texts), 9))\n",
    "        for i in range(len(texts)):\n",
    "            out[i,:] = predict_one_sentence(texts[i], word_index)\n",
    "\n",
    "        return out\n",
    "    return predict_func\n",
    "\n",
    "word_idx = 6\n",
    "func = get_predict_function(word_idx)\n",
    "sampler = MaskingTextSampler(\n",
    "    replacement=\"UNK\",\n",
    "    max_replace=0.7,\n",
    "    token_pattern=None,\n",
    "    bow=False\n",
    ")\n",
    "\n",
    "samples, similarity = sampler.sample_near(text, n_samples=5)\n",
    "print(samples)\n",
    "\n",
    "te = TextExplainer(n_samples=5000, sampler=sampler, position_dependent=True, random_state=42)\n",
    "te.fit(text, func)\n",
    "\n",
    "tag_names = ['O', 'geo', 'tim', 'org', 'per', 'gpe', 'art', 'eve', 'nat']\n",
    "\n",
    "#the explainer needs just the one instance text from texts list\n",
    "explain = te.explain_prediction(target_names=tag_names,top_targets=3)\n",
    "print(\"WORD TO EXPLAIN\", s[word_idx])\n",
    "explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5de96e7bd8395409e1c7b7832f2239ec7bd9680ead0db1c40194c8a312bf7c20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
