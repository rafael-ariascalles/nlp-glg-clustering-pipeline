{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1351,
   "id": "7eda96da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1352,
   "id": "f7817ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 4)"
      ]
     },
     "execution_count": 1352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/'\n",
    "df = pd.read_csv(data_path + 'ner_dataset.zip', encoding=\"latin1\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1353,
   "id": "095d18fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 1353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc7bb09",
   "metadata": {},
   "source": [
    "## Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1354,
   "id": "9d08ee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep all numbers, all letters and hyphens\n",
    "df['tidy_word'] = df['Word'].apply(lambda x: re.sub(\"[^a-zA-Z0-9\\-]\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "id": "b068b00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove observations that are now empty\n",
    "df = df[df['tidy_word'] != '']\n",
    "\n",
    "# Hyphenated words are kept as a single token\n",
    "# in this dataset. Remove observations that\n",
    "# are a between-word dash. This causes problems\n",
    "# with the algorithm\n",
    "df = df[df['tidy_word'] != '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1356,
   "id": "67f34b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later steps require a consecutive index\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7dcb7c",
   "metadata": {},
   "source": [
    "### Create Sentence Form of Text\n",
    "\n",
    "We create a new Series where each row is a list with the contents of a sentence. We do this so that it can be more easily sent to Spacy NER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1357,
   "id": "48a0bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toSentenceForm(df, var):\n",
    "    \"\"\"\n",
    "    From a Series:\n",
    "    \n",
    "        Sentence  #      var\n",
    "        -----------  -------\n",
    "        Sentence: 1     Mary\n",
    "                NaN      had\n",
    "                NaN        a\n",
    "                NaN   little\n",
    "                NaN     lamb\n",
    "                NaN        .\n",
    "        Sentence: 2       He\n",
    "                NaN followed\n",
    "                NaN      her\n",
    "                \n",
    "    to a list of lists of strings by sentence:\n",
    "    \n",
    "        [['Mary', 'had', 'a', 'little', 'lamb' '.'],\n",
    "         ['He', 'followed', 'her', ...]]\n",
    "                                \n",
    "    \"\"\"\n",
    "    sent_out = []\n",
    "\n",
    "    # Find the index of each sentence start\n",
    "    idx = df['Sentence #'].isna()\n",
    "    sent_breaks = df[idx == False].index\n",
    "    \n",
    "    \n",
    "    for i in range(len(sent_breaks)-1):\n",
    "        \n",
    "        # Create a list containing all strings\n",
    "        # from the current sentence\n",
    "        out = []\n",
    "        for j in range(sent_breaks[i], sent_breaks[i+1]):\n",
    "            out.append(df[var].iloc[j])\n",
    "        \n",
    "        # Append ith sentence list to the\n",
    "        # list of all sentences\n",
    "        sent_out.append(out)\n",
    "\n",
    "    return sent_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "id": "eb96512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = toSentenceForm(df, 'tidy_word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1359,
   "id": "6fb9a66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = toSentenceForm(df, 'Tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1360,
   "id": "a7de0f90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "se = pd.DataFrame({'sentence_list': sentences, 'tags': tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1361,
   "id": "5a4e2853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_list</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Families, of, soldiers, killed, in, the, conf...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[They, marched, from, the, Houses, of, Parliam...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-geo, I-geo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Police, put, the, number, of, marchers, at, 1...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The, protest, comes, on, the, eve, of, the, a...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-geo, O, O,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       sentence_list  \\\n",
       "0  [Thousands, of, demonstrators, have, marched, ...   \n",
       "1  [Families, of, soldiers, killed, in, the, conf...   \n",
       "2  [They, marched, from, the, Houses, of, Parliam...   \n",
       "3  [Police, put, the, number, of, marchers, at, 1...   \n",
       "4  [The, protest, comes, on, the, eve, of, the, a...   \n",
       "\n",
       "                                                tags  \n",
       "0  [O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...  \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2    [O, O, O, O, O, O, O, O, O, O, O, B-geo, I-geo]  \n",
       "3         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, B-geo, O, O,...  "
      ]
     },
     "execution_count": 1361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1362,
   "id": "7df87dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "se.to_csv('../data/ner_sentences.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e74465",
   "metadata": {},
   "source": [
    "### Perform NER\n",
    "\n",
    "Spacy will automatically perform NER when we create a Doc object from a sentence.\n",
    "\n",
    "Iterate over all words and tags in the Doc object and create lists of tokens and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1363,
   "id": "60a9ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "id": "1e887f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0:\t47839 (0.00%)\n",
      "      2500:\t47839 (5.23%)\n",
      "      5000:\t47839 (10.45%)\n",
      "      7500:\t47839 (15.68%)\n",
      "     10000:\t47839 (20.90%)\n",
      "     12500:\t47839 (26.13%)\n",
      "     15000:\t47839 (31.36%)\n",
      "     17500:\t47839 (36.58%)\n",
      "     20000:\t47839 (41.81%)\n",
      "     22500:\t47839 (47.03%)\n",
      "     25000:\t47839 (52.26%)\n",
      "     27500:\t47839 (57.48%)\n",
      "     30000:\t47839 (62.71%)\n",
      "     32500:\t47839 (67.94%)\n",
      "     35000:\t47839 (73.16%)\n",
      "     37500:\t47839 (78.39%)\n",
      "     40000:\t47839 (83.61%)\n",
      "     42500:\t47839 (88.84%)\n",
      "     45000:\t47839 (94.07%)\n",
      "     47500:\t47839 (99.29%)\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "spacy_tags = []\n",
    "doc = nlp(fs)\n",
    "ctr = 0\n",
    "\n",
    "# number of iterations between progress report\n",
    "report_freq = 2500\n",
    "\n",
    "for row, sentence in enumerate(se['sentence_list']):\n",
    "    doc = nlp(' '.join(sentence))\n",
    "\n",
    "    # Print progress report\n",
    "    if row == int(row / report_freq) * report_freq:\n",
    "        print(f'{row:10.9g}:\\t{se.shape[0]} ({100*row/se.shape[0]:.2f}%)')\n",
    "    \n",
    "    # Iterate over tokens in doc\n",
    "    # and create lists of tokens and tags\n",
    "    for i, t in enumerate(doc):\n",
    "        words.append(t)\n",
    "        if t.ent_iob_ == 'O':\n",
    "            spacy_tags.append('O')\n",
    "        else:\n",
    "            spacy_tags.append(t.ent_iob_+'-'+t.ent_type_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "id": "fa7d55a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spacy = pd.DataFrame({'Words': words, 'Tags': spacy_tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1391,
   "id": "ac607836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(981669, 2)"
      ]
     },
     "execution_count": 1391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spacy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1392,
   "id": "8749dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spacy.to_csv('../data/ner_spacy_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1393,
   "id": "286c68c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>B-CARDINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>through</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>London</td>\n",
       "      <td>B-GPE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Words        Tags\n",
       "0      Thousands  B-CARDINAL\n",
       "1             of           O\n",
       "2  demonstrators           O\n",
       "3           have           O\n",
       "4        marched           O\n",
       "5        through           O\n",
       "6         London       B-GPE"
      ]
     },
     "execution_count": 1393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spacy.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "id": "2683b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def containsHyphen(s):\n",
    "    return len(s) > 1 and (s.find('-') > -1)\n",
    "\n",
    "def findHyphenatedWord(s, s_list, idx):\n",
    "    return s + s_list[idx+1] + s_list[idx+2]\n",
    "\n",
    "def findAdditionalHyphens(s, s_list, idx, inc):\n",
    "        finished = 1\n",
    "        idx += inc\n",
    "        if idx < len(s_list) and s_list[idx] == '-':\n",
    "            s = findHyphenatedWord(s, s_list, idx-1)\n",
    "            finished = 0\n",
    "            return (idx, s, finished)\n",
    "        else:\n",
    "            return (idx, s, finished)\n",
    "\n",
    "def findHyphenatedWords(s_list, idx):\n",
    "    s = s_list[idx]\n",
    "    s = findHyphenatedWord(s, s_list, idx)\n",
    "    \n",
    "    finished = 0  # have we found all connected hyphens?\n",
    "    increment = 3 # the first additional hyphen is further than\n",
    "                  # subsequent ones, because the original 'idx'\n",
    "                  # is pointing at a word, but the after calling\n",
    "                  # findAdditionalHyphens() 'idx' will point at a\n",
    "                  # hyphen after the word\n",
    "                  \n",
    "    \n",
    "    while finished == 0:\n",
    "        idx, s, finished = findAdditionalHyphens(s, s_list, idx, increment)\n",
    "        increment = 2\n",
    "                \n",
    "\n",
    "    return (idx, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1395,
   "id": "6ad1ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [ 'apple', 'apple-jacks', 'chocolate', 'coco-puffs-again', \n",
    "     'old-mcdonald-had-a-farm']\n",
    "b = [ 'apple', 'apple', '-', 'jacks', 'chocolate', 'coco', \n",
    "     '-', 'puffs', '-', 'again', 'old', '-', 'mcdonald', '-', 'had', \n",
    "     '-', 'a', '-', 'farm']\n",
    "\n",
    "def test_findHyphenatedWords(a, b):\n",
    "    c = []\n",
    "    i = 0\n",
    "    for ai in (a):\n",
    "        if containsHyphen(ai):\n",
    "            i, ss = findHyphenatedWords(b, i)\n",
    "            c.append(ss)\n",
    "        else:\n",
    "            c.append(b[i])\n",
    "            i += 1\n",
    "\n",
    "    c_cmp = ['apple',\n",
    "             'apple-jacks',\n",
    "             'chocolate',\n",
    "             'coco-puffs-again',\n",
    "             'old-mcdonald-had-a-farm']\n",
    "\n",
    "    return c == c_cmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1396,
   "id": "75f74963",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert test_findHyphenatedWords(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6ff9b7",
   "metadata": {},
   "source": [
    "### Align tokens and tags\n",
    "\n",
    "Spacy breaks up some words differently than our dataset. Below, we create a list of the tokens from our original dataset and their Spacy tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1401,
   "id": "a4532788",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "i: 168074 j: 171909 c: ['wont'] word: \"wont\", sp_word[0]: \"[wo, nt]\"\n",
      "done\n",
      "i: 189964 j: 194298 c: ['wed'] word: \"wed\", sp_word[0]: \"[we, d]\"\n"
     ]
    }
   ],
   "source": [
    "c = []\n",
    "s_tags = []\n",
    "i = 0\n",
    "j = 0\n",
    "supress_til = 1780\n",
    "for word in df['tidy_word']:\n",
    "    if containsHyphen(word):\n",
    "        # grabbing a bunch of words in case we have to search\n",
    "        # and grab more tokens from hyphenated words\n",
    "        sp_word = [w.text for w in df_spacy['Words'].iloc[j:j+9]]\n",
    "        if sp_word[0] == word:\n",
    "            sp_tag_tmp = df_spacy['Tags'].iloc[j]\n",
    "            s_tags.append(sp_tag_tmp)\n",
    "            c.append(word)\n",
    "            \n",
    "            j += 1\n",
    "        else:\n",
    "            k = 0\n",
    "            k, ss = findHyphenatedWords(sp_word, k)\n",
    "            \n",
    "            sp_tag_tmp = df_spacy['Tags'].iloc[j]\n",
    "            s_tags.append(sp_tag_tmp)\n",
    "            \n",
    "            j += k\n",
    "            \n",
    "            c.append(ss)\n",
    "    else:\n",
    "        next_sp_word_ = df_spacy[\"Words\"].iloc[j]\n",
    "        if len(word) > 1 and word.endswith('.'):\n",
    "            next_sp_word = df_spacy[\"Words\"].iloc[j+1]\n",
    "            if next_sp_word.text == '.':\n",
    "                j += 1\n",
    "                \n",
    "        sp_tag_tmp = df_spacy['Tags'].iloc[j]\n",
    "        s_tags.append(sp_tag_tmp)\n",
    "        c.append(next_sp_word_.text)\n",
    "        j += 1\n",
    "        \n",
    "    i += 1\n",
    "    if len(c) == 500000:\n",
    "        break\n",
    "        \n",
    "    if c[-1] != word:\n",
    "        # try and take care of times where Spacy splits 'wont', 'wed'\n",
    "        tmpa = df_spacy[\"Words\"].iloc[j]\n",
    "        tmp = c[-1] + tmpa.text\n",
    "        if tmp == word:\n",
    "            c[-1] = tmp\n",
    "            \n",
    "        j += 1\n",
    "            \n",
    "        print('done')\n",
    "        print(f'i: {i} j: {j} c: {c[-1:]} word: \"{word}\", sp_word[0]: \"{list(df_spacy[\"Words\"].iloc[j-2:j])}\"')\n",
    "#         break\n",
    "    last_word = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1402,
   "id": "f2d484cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-CARDINAL' 'B-DATE' 'B-EVENT' 'B-FAC' 'B-GPE' 'B-LANGUAGE' 'B-LAW'\n",
      " 'B-LOC' 'B-MONEY' 'B-NORP' 'B-ORDINAL' 'B-ORG' 'B-PERCENT' 'B-PERSON'\n",
      " 'B-PRODUCT' 'B-QUANTITY' 'B-TIME' 'B-WORK_OF_ART' 'I-CARDINAL' 'I-DATE'\n",
      " 'I-EVENT' 'I-FAC' 'I-GPE' 'I-LAW' 'I-LOC' 'I-MONEY' 'I-NORP' 'I-ORG'\n",
      " 'I-PERCENT' 'I-PERSON' 'I-PRODUCT' 'I-QUANTITY' 'I-TIME' 'I-WORK_OF_ART'\n",
      " 'O']\n"
     ]
    }
   ],
   "source": [
    "all_spacy_tags = np.unique(s_tags)\n",
    "print(all_spacy_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1403,
   "id": "f21254af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>B-CARDINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           token         tag\n",
       "0      Thousands  B-CARDINAL\n",
       "1             of           O\n",
       "2  demonstrators           O\n",
       "3           have           O\n",
       "4        marched           O"
      ]
     },
     "execution_count": 1403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_word_tag = pd.DataFrame({'token': c, 'tag': s_tags})\n",
    "spacy_word_tag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1404,
   "id": "1e2a6184",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_word_tag.to_csv('../data/ner_spacy_aligned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f18802",
   "metadata": {},
   "source": [
    "## Examine performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1658,
   "id": "9cea4972",
   "metadata": {},
   "outputs": [],
   "source": [
    "swt = spacy_word_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1659,
   "id": "0d126b07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>tag</th>\n",
       "      <th>tag2</th>\n",
       "      <th>dftag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>B-CARDINAL</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           token         tag tag2 dftag\n",
       "0      Thousands  B-CARDINAL    O     O\n",
       "1             of           O    O     O\n",
       "2  demonstrators           O    O     O\n",
       "3           have           O    O     O\n",
       "4        marched           O    O     O"
      ]
     },
     "execution_count": 1659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fcc3a2",
   "metadata": {},
   "source": [
    "### Make sure all tokens match\n",
    "\n",
    "Here we verify that the tokens from our training data match the tokens we created for the Spacy predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1660,
   "id": "baf7ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tok in enumerate(swt['token']):\n",
    "    if tok != df['tidy_word'].iloc[i]:\n",
    "        print(tok, df['tidy_word'].iloc[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fd284c",
   "metadata": {},
   "source": [
    "### Remove 'I' and 'B' tags\n",
    "\n",
    "We want to get a preliminary look at the performance and not (at least not yet) worry about which token is used as the starting token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1661,
   "id": "f8faaffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tag2'] = df['Tag'].apply(lambda tok: tok.replace('I-', ''))\n",
    "df['Tag2'] = df['Tag2'].apply(lambda tok: tok.replace('B-', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03f2ae4",
   "metadata": {},
   "source": [
    "### Convert Spacy tags\n",
    "\n",
    "Here we try and translate the Spacy tags to the same representation as our training data.\n",
    "\n",
    "PERSON:      People, including fictional.<br/>\n",
    "NORP:        Nationalities or religious or political groups.<br/>\n",
    "FAC:         Buildings, airports, highways, bridges, etc.<br/>\n",
    "ORG:         Companies, agencies, institutions, etc.<br/>\n",
    "GPE:         Countries, cities, states.<br/>\n",
    "LOC:         Non-GPE locations, mountain ranges, bodies of water.<br/>\n",
    "PRODUCT:     Objects, vehicles, foods, etc. (Not services.)<br/>\n",
    "EVENT:       Named hurricanes, battles, wars, sports events, etc.<br/>\n",
    "WORK_OF_ART: Titles of books, songs, etc.<br/>\n",
    "LAW:         Named documents made into laws.<br/>\n",
    "LANGUAGE:    Any named language.<br/>\n",
    "DATE:        Absolute or relative dates or periods.<br/>\n",
    "TIME:        Times smaller than a day.<br/>\n",
    "PERCENT:     Percentage, including ”%“.<br/>\n",
    "MONEY:       Monetary values, including unit.<br/>\n",
    "QUANTITY:    Measurements, as of weight or distance.<br/>\n",
    "ORDINAL:     “first”, “second”, etc.<br/>\n",
    "CARDINAL:    Numerals that do not fall under another type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1691,
   "id": "b29ed049",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy2ref = {'GPE': 'gpe', 'ORG': 'org', 'PERSON': 'per', 'DATE': 'date',\n",
    "             'TIME': 'tim', 'EVENT': 'eve', 'LOC': 'geo', 'ORDINAL': 'O',\n",
    "             'CARDINAL': 'O', 'MONEY': 'O', 'PERCENT': 'O', 'GEO': 'geo', \n",
    "             'QUANTITY': 'O', 'FAC': 'geo'}\n",
    "\n",
    "swt['tag2'] = swt['tag'].apply(lambda tok: tok.replace('I-', ''))\n",
    "swt['tag2'] = swt['tag2'].apply(lambda tok: tok.replace('B-', ''))\n",
    "for k in spacy2ref:\n",
    "    swt['tag2'] = swt['tag2'].apply(lambda tok: tok.replace(k, spacy2ref[k]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1692,
   "id": "577feaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O              409804\n",
       "gpe             21965\n",
       "date            20132\n",
       "org             17595\n",
       "per             14008\n",
       "NORP            10464\n",
       "geo              3199\n",
       "eve              1209\n",
       "tim               883\n",
       "PRODUCT           251\n",
       "WORK_OF_ART       248\n",
       "LAW               196\n",
       "LANGUAGE           46\n",
       "Name: tag2, dtype: int64"
      ]
     },
     "execution_count": 1692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out how many observations we have for each Spacy tag\n",
    "swt['tag2'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb16442",
   "metadata": {},
   "source": [
    "### Check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1693,
   "id": "548d4c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMatches(df, swt):\n",
    "    \"\"\"\n",
    "    Create binary vector of size swt.shape[0] with a one\n",
    "    for every element where the tags match and a 0 otherwise.\n",
    "    \n",
    "    Also return a count of the number of misses and number of matches.\n",
    "    \"\"\"\n",
    "    match_idx = np.zeros(swt.shape[0])\n",
    "    match = 0\n",
    "    miss = 0\n",
    "    for i, tok in enumerate(swt):\n",
    "        if tok != df.iloc[i]:\n",
    "            miss += 1\n",
    "        else:\n",
    "            match += 1\n",
    "            match_idx[i] = 1\n",
    "    \n",
    "    return (match, miss, match_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1694,
   "id": "891bff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "match, miss, match_idx = findMatches(df['Tag2'], swt['tag2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675b6abd",
   "metadata": {},
   "source": [
    "Here we see about 85% accuracy. However, this data is quite imbalanced, so we need to check and see if the success is just limited to prediction of the dominant class ('O')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1695,
   "id": "2c6dc3f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.847604, 0.152396)"
      ]
     },
     "execution_count": 1695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(match/swt.shape[0], miss/swt.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1696,
   "id": "50d185ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into observations where the tags\n",
    "# match and observations that do not match\n",
    "cmp = swt[['token', 'tag2']].copy()\n",
    "cmp['dftag'] = df['Tag2']\n",
    "cmp_match = cmp[match_idx == 1]\n",
    "cmp_miss = cmp[match_idx == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1697,
   "id": "f46177c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missMatchTable(cmp_match, cmp_miss):\n",
    "    return pd.DataFrame({'miss': cmp_miss['dftag'].value_counts(), 'match': cmp_match['dftag'].value_counts(), 'pct correct': cmp_match['dftag'].value_counts() / (cmp_match['dftag'].value_counts() + cmp_miss['dftag'].value_counts())})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be78197",
   "metadata": {},
   "source": [
    "In the table printed below, we can see that the 'geo' and 'gpe' tags are performing terribly. This could be because of differing definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1698,
   "id": "cdb69f6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>miss</th>\n",
       "      <th>match</th>\n",
       "      <th>pct correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>18385</td>\n",
       "      <td>398365.0</td>\n",
       "      <td>0.955885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>art</th>\n",
       "      <td>366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eve</th>\n",
       "      <td>156</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.551724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geo</th>\n",
       "      <td>21473</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>0.085009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpe</th>\n",
       "      <td>7771</td>\n",
       "      <td>716.0</td>\n",
       "      <td>0.084364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nat</th>\n",
       "      <td>142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>org</th>\n",
       "      <td>7605</td>\n",
       "      <td>11144.0</td>\n",
       "      <td>0.594378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per</th>\n",
       "      <td>7031</td>\n",
       "      <td>11081.0</td>\n",
       "      <td>0.611804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tim</th>\n",
       "      <td>13269</td>\n",
       "      <td>309.0</td>\n",
       "      <td>0.022757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      miss     match  pct correct\n",
       "O    18385  398365.0     0.955885\n",
       "art    366       NaN          NaN\n",
       "eve    156     192.0     0.551724\n",
       "geo  21473    1995.0     0.085009\n",
       "gpe   7771     716.0     0.084364\n",
       "nat    142       NaN          NaN\n",
       "org   7605   11144.0     0.594378\n",
       "per   7031   11081.0     0.611804\n",
       "tim  13269     309.0     0.022757"
      ]
     },
     "execution_count": 1698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missMatchTable(cmp_match, cmp_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1699,
   "id": "994ccb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missTags(cmp_miss, tag_true):\n",
    "    tag_counts = cmp_miss[cmp_miss['dftag'] == tag_true]['tag2'].value_counts()\n",
    "    samples = cmp_miss[cmp_miss['dftag'] == tag_true][['token', 'tag2']]\n",
    "    return tag_counts, samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78593c9e",
   "metadata": {},
   "source": [
    "As we suspect, most of the \"incorrect\" 'geo' tags are marked as 'gpe'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1700,
   "id": "dad6cb99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gpe            17130\n",
       "org             1397\n",
       "O               1355\n",
       "per              884\n",
       "NORP             501\n",
       "eve               69\n",
       "PRODUCT           56\n",
       "date              39\n",
       "WORK_OF_ART       23\n",
       "tim                8\n",
       "LAW                6\n",
       "LANGUAGE           5\n",
       "Name: tag2, dtype: int64"
      ]
     },
     "execution_count": 1700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_counts, mistakes = missTags(cmp_miss, 'geo')\n",
    "tag_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb7dbc3",
   "metadata": {},
   "source": [
    "The table below shows that the vast majority of the tokens \"mislabeled\" as 'gpe', appear quite reasonably labeled as 'gpe'. It is possible that one of the models is using context better than the other.\n",
    "\n",
    "The top 50 by count account for more than 50% of the \"mislabeled\" 'geo' tags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1701,
   "id": "45c65fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11959"
      ]
     },
     "execution_count": 1701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistakes.value_counts().iloc[0:50].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1702,
   "id": "de9d6c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "token        tag2\n",
       "US           gpe     1622\n",
       "Iraq         gpe      884\n",
       "United       gpe      656\n",
       "States       gpe      655\n",
       "Iran         gpe      552\n",
       "Afghanistan  gpe      506\n",
       "Israel       gpe      466\n",
       "China        gpe      439\n",
       "Baghdad      gpe      398\n",
       "Pakistan     gpe      377\n",
       "Russia       gpe      305\n",
       "Gaza         gpe      254\n",
       "Korea        gpe      250\n",
       "Washington   gpe      238\n",
       "India        gpe      234\n",
       "New          gpe      186\n",
       "UN           org      176\n",
       "Venezuela    gpe      172\n",
       "Japan        gpe      171\n",
       "South        gpe      170\n",
       "North        gpe      170\n",
       "Lebanon      gpe      160\n",
       "Syria        gpe      159\n",
       "Britain      gpe      158\n",
       "Burma        gpe      145\n",
       "Somalia      gpe      129\n",
       "France       gpe      129\n",
       "Germany      gpe      124\n",
       "Strip        gpe      116\n",
       "Cuba         gpe      116\n",
       "London       gpe      115\n",
       "Darfur       gpe      115\n",
       "Beijing      gpe      110\n",
       "southern     O        104\n",
       "Sudan        gpe      102\n",
       "Turkey       gpe       99\n",
       "Indonesia    gpe       99\n",
       "Haiti        gpe       97\n",
       "Moscow       gpe       96\n",
       "Colombia     gpe       93\n",
       "Tehran       gpe       91\n",
       "Ukraine      gpe       87\n",
       "York         gpe       87\n",
       "Mexico       gpe       84\n",
       "Republic     gpe       80\n",
       "Nigeria      gpe       80\n",
       "Taiwan       gpe       79\n",
       "the          O         76\n",
       "Africa       gpe       75\n",
       "Egypt        gpe       73\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistakes.value_counts().iloc[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50461bda",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b5611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f2fd13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
