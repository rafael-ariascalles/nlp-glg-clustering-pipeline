{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7eda96da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7817ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 4)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/'\n",
    "df = pd.read_csv(data_path + 'ner_dataset.zip', encoding=\"latin1\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "095d18fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc7bb09",
   "metadata": {},
   "source": [
    "## Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9d08ee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep all numbers, all letters and hyphens\n",
    "df['tidy_word'] = df['Word'].apply(lambda x: re.sub(\"[^a-zA-Z0-9\\-]\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b068b00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove observations that are now empty\n",
    "df = df[df['tidy_word'] != '']\n",
    "\n",
    "# Hyphenated words are kept as a single token\n",
    "# in this dataset. Remove observations that\n",
    "# are a between-word dash. This causes problems\n",
    "# with the algorithm\n",
    "df = df[df['tidy_word'] != '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "67f34b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later steps require a consecutive index\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7dcb7c",
   "metadata": {},
   "source": [
    "### Create Sentence Form of Text\n",
    "\n",
    "We create a new Series where each row is a list with the contents of a sentence. We do this so that it can be more easily sent to Spacy NER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "48a0bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toSentenceForm(df, var):\n",
    "    \"\"\"\n",
    "    From a Series:\n",
    "    \n",
    "        Sentence  #      var\n",
    "        -----------  -------\n",
    "        Sentence: 1     Mary\n",
    "                NaN      had\n",
    "                NaN        a\n",
    "                NaN   little\n",
    "                NaN     lamb\n",
    "                NaN        .\n",
    "        Sentence: 2       He\n",
    "                NaN followed\n",
    "                NaN      her\n",
    "                \n",
    "    to a list of lists of strings by sentence:\n",
    "    \n",
    "        [['Mary', 'had', 'a', 'little', 'lamb' '.'],\n",
    "         ['He', 'followed', 'her', ...]]\n",
    "                                \n",
    "    \"\"\"\n",
    "    sent_out = []\n",
    "\n",
    "    # Find the index of each sentence start\n",
    "    idx = df['Sentence #'].isna()\n",
    "    sent_breaks = df[idx == False].index\n",
    "    \n",
    "    \n",
    "    for i in range(len(sent_breaks)-1):\n",
    "        \n",
    "        # Create a list containing all strings\n",
    "        # from the current sentence\n",
    "        out = []\n",
    "        for j in range(sent_breaks[i], sent_breaks[i+1]):\n",
    "            out.append(df[var].iloc[j])\n",
    "        \n",
    "        # Append ith sentence list to the\n",
    "        # list of all sentences\n",
    "        sent_out.append(out)\n",
    "\n",
    "    return sent_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eb96512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = toSentenceForm(df, 'tidy_word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6fb9a66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = toSentenceForm(df, 'Tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a7de0f90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "se = pd.DataFrame({'sentence_list': sentences, 'tags': tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5a4e2853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_list</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Families, of, soldiers, killed, in, the, conf...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[They, marched, from, the, Houses, of, Parliam...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-geo, I-geo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Police, put, the, number, of, marchers, at, 1...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The, protest, comes, on, the, eve, of, the, a...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-geo, O, O,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       sentence_list  \\\n",
       "0  [Thousands, of, demonstrators, have, marched, ...   \n",
       "1  [Families, of, soldiers, killed, in, the, conf...   \n",
       "2  [They, marched, from, the, Houses, of, Parliam...   \n",
       "3  [Police, put, the, number, of, marchers, at, 1...   \n",
       "4  [The, protest, comes, on, the, eve, of, the, a...   \n",
       "\n",
       "                                                tags  \n",
       "0  [O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...  \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2    [O, O, O, O, O, O, O, O, O, O, O, B-geo, I-geo]  \n",
       "3         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, B-geo, O, O,...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7df87dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "se.to_csv('../data/ner_sentences.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e74465",
   "metadata": {},
   "source": [
    "### Perform NER\n",
    "\n",
    "Spacy will automatically perform NER when we create a Doc object from a sentence.\n",
    "\n",
    "Iterate over all words and tags in the Doc object and create lists of tokens and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "60a9ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e887f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0:\t47839 (0.00%)\n",
      "      2500:\t47839 (5.23%)\n",
      "      5000:\t47839 (10.45%)\n",
      "      7500:\t47839 (15.68%)\n",
      "     10000:\t47839 (20.90%)\n",
      "     12500:\t47839 (26.13%)\n",
      "     15000:\t47839 (31.36%)\n",
      "     17500:\t47839 (36.58%)\n",
      "     20000:\t47839 (41.81%)\n",
      "     22500:\t47839 (47.03%)\n",
      "     25000:\t47839 (52.26%)\n",
      "     27500:\t47839 (57.48%)\n",
      "     30000:\t47839 (62.71%)\n",
      "     32500:\t47839 (67.94%)\n",
      "     35000:\t47839 (73.16%)\n",
      "     37500:\t47839 (78.39%)\n",
      "     40000:\t47839 (83.61%)\n",
      "     42500:\t47839 (88.84%)\n",
      "     45000:\t47839 (94.07%)\n",
      "     47500:\t47839 (99.29%)\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "spacy_tags = []\n",
    "ctr = 0\n",
    "\n",
    "# number of iterations between progress report\n",
    "report_freq = 2500\n",
    "\n",
    "for row, sentence in enumerate(se['sentence_list']):\n",
    "    doc = nlp(' '.join(sentence))\n",
    "\n",
    "    # Print progress report\n",
    "    if row == int(row / report_freq) * report_freq:\n",
    "        print(f'{row:10.9g}:\\t{se.shape[0]} ({100*row/se.shape[0]:.2f}%)')\n",
    "    \n",
    "    # Iterate over tokens in doc\n",
    "    # and create lists of tokens and tags\n",
    "    for i, t in enumerate(doc):\n",
    "        words.append(t)\n",
    "        if t.ent_iob_ == 'O':\n",
    "            spacy_tags.append('O')\n",
    "        else:\n",
    "            spacy_tags.append(t.ent_iob_+'-'+t.ent_type_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa7d55a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spacy = pd.DataFrame({'Words': words, 'Tags': spacy_tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac607836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(981669, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spacy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8749dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spacy.to_csv('../data/ner_spacy_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "286c68c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>B-CARDINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>through</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>London</td>\n",
       "      <td>B-GPE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Words        Tags\n",
       "0      Thousands  B-CARDINAL\n",
       "1             of           O\n",
       "2  demonstrators           O\n",
       "3           have           O\n",
       "4        marched           O\n",
       "5        through           O\n",
       "6         London       B-GPE"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spacy.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2683b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def containsHyphen(s):\n",
    "    return len(s) > 1 and (s.find('-') > -1)\n",
    "\n",
    "def findHyphenatedWord(s, s_list, idx):\n",
    "    return s + s_list[idx+1] + s_list[idx+2]\n",
    "\n",
    "def findAdditionalHyphens(s, s_list, idx, inc):\n",
    "        finished = 1\n",
    "        idx += inc\n",
    "        if idx < len(s_list) and s_list[idx] == '-':\n",
    "            s = findHyphenatedWord(s, s_list, idx-1)\n",
    "            finished = 0\n",
    "            return (idx, s, finished)\n",
    "        else:\n",
    "            return (idx, s, finished)\n",
    "\n",
    "def findHyphenatedWords(s_list, idx):\n",
    "    s = s_list[idx]\n",
    "    s = findHyphenatedWord(s, s_list, idx)\n",
    "    \n",
    "    finished = 0  # have we found all connected hyphens?\n",
    "    increment = 3 # the first additional hyphen is further than\n",
    "                  # subsequent ones, because the original 'idx'\n",
    "                  # is pointing at a word, but the after calling\n",
    "                  # findAdditionalHyphens() 'idx' will point at a\n",
    "                  # hyphen after the word\n",
    "                  \n",
    "    \n",
    "    while finished == 0:\n",
    "        idx, s, finished = findAdditionalHyphens(s, s_list, idx, increment)\n",
    "        increment = 2\n",
    "                \n",
    "\n",
    "    return (idx, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ad1ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [ 'apple', 'apple-jacks', 'chocolate', 'coco-puffs-again', \n",
    "     'old-mcdonald-had-a-farm']\n",
    "b = [ 'apple', 'apple', '-', 'jacks', 'chocolate', 'coco', \n",
    "     '-', 'puffs', '-', 'again', 'old', '-', 'mcdonald', '-', 'had', \n",
    "     '-', 'a', '-', 'farm']\n",
    "\n",
    "def test_findHyphenatedWords(a, b):\n",
    "    c = []\n",
    "    i = 0\n",
    "    for ai in (a):\n",
    "        if containsHyphen(ai):\n",
    "            i, ss = findHyphenatedWords(b, i)\n",
    "            c.append(ss)\n",
    "        else:\n",
    "            c.append(b[i])\n",
    "            i += 1\n",
    "\n",
    "    c_cmp = ['apple',\n",
    "             'apple-jacks',\n",
    "             'chocolate',\n",
    "             'coco-puffs-again',\n",
    "             'old-mcdonald-had-a-farm']\n",
    "\n",
    "    return c == c_cmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75f74963",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert test_findHyphenatedWords(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6ff9b7",
   "metadata": {},
   "source": [
    "### Align tokens and tags\n",
    "\n",
    "Spacy breaks up some words differently than our dataset. Below, we create a list of the tokens from our original dataset and their Spacy tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4532788",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "i: 168074 j: 171909 c: ['wont'] word: \"wont\", sp_word[0]: \"[wo, nt]\"\n",
      "done\n",
      "i: 189964 j: 194298 c: ['wed'] word: \"wed\", sp_word[0]: \"[we, d]\"\n"
     ]
    }
   ],
   "source": [
    "c = []\n",
    "s_tags = []\n",
    "i = 0\n",
    "j = 0\n",
    "supress_til = 1780\n",
    "for word in df['tidy_word']:\n",
    "    if containsHyphen(word):\n",
    "        # grabbing a bunch of words in case we have to search\n",
    "        # and grab more tokens from hyphenated words\n",
    "        sp_word = [w.text for w in df_spacy['Words'].iloc[j:j+9]]\n",
    "        if sp_word[0] == word:\n",
    "            sp_tag_tmp = df_spacy['Tags'].iloc[j]\n",
    "            s_tags.append(sp_tag_tmp)\n",
    "            c.append(word)\n",
    "            \n",
    "            j += 1\n",
    "        else:\n",
    "            k = 0\n",
    "            k, ss = findHyphenatedWords(sp_word, k)\n",
    "            \n",
    "            sp_tag_tmp = df_spacy['Tags'].iloc[j]\n",
    "            s_tags.append(sp_tag_tmp)\n",
    "            \n",
    "            j += k\n",
    "            \n",
    "            c.append(ss)\n",
    "    else:\n",
    "        next_sp_word_ = df_spacy[\"Words\"].iloc[j]\n",
    "        if len(word) > 1 and word.endswith('.'):\n",
    "            next_sp_word = df_spacy[\"Words\"].iloc[j+1]\n",
    "            if next_sp_word.text == '.':\n",
    "                j += 1\n",
    "                \n",
    "        sp_tag_tmp = df_spacy['Tags'].iloc[j]\n",
    "        s_tags.append(sp_tag_tmp)\n",
    "        c.append(next_sp_word_.text)\n",
    "        j += 1\n",
    "        \n",
    "    i += 1\n",
    "    if len(c) == 500000:\n",
    "        break\n",
    "        \n",
    "    if c[-1] != word:\n",
    "        # try and take care of times where Spacy splits 'wont', 'wed'\n",
    "        tmpa = df_spacy[\"Words\"].iloc[j]\n",
    "        tmp = c[-1] + tmpa.text\n",
    "        if tmp == word:\n",
    "            c[-1] = tmp\n",
    "            \n",
    "        j += 1\n",
    "            \n",
    "        print('done')\n",
    "        print(f'i: {i} j: {j} c: {c[-1:]} word: \"{word}\", sp_word[0]: \"{list(df_spacy[\"Words\"].iloc[j-2:j])}\"')\n",
    "#         break\n",
    "    last_word = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2d484cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-CARDINAL' 'B-DATE' 'B-EVENT' 'B-FAC' 'B-GPE' 'B-LANGUAGE' 'B-LAW'\n",
      " 'B-LOC' 'B-MONEY' 'B-NORP' 'B-ORDINAL' 'B-ORG' 'B-PERCENT' 'B-PERSON'\n",
      " 'B-PRODUCT' 'B-QUANTITY' 'B-TIME' 'B-WORK_OF_ART' 'I-CARDINAL' 'I-DATE'\n",
      " 'I-EVENT' 'I-FAC' 'I-GPE' 'I-LAW' 'I-LOC' 'I-MONEY' 'I-NORP' 'I-ORG'\n",
      " 'I-PERCENT' 'I-PERSON' 'I-PRODUCT' 'I-QUANTITY' 'I-TIME' 'I-WORK_OF_ART'\n",
      " 'O']\n"
     ]
    }
   ],
   "source": [
    "all_spacy_tags = np.unique(s_tags)\n",
    "print(all_spacy_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f21254af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>B-CARDINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           token         tag\n",
       "0      Thousands  B-CARDINAL\n",
       "1             of           O\n",
       "2  demonstrators           O\n",
       "3           have           O\n",
       "4        marched           O"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_word_tag = pd.DataFrame({'token': c, 'tag': s_tags})\n",
    "spacy_word_tag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e2a6184",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_word_tag.to_csv('../data/ner_spacy_aligned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f18802",
   "metadata": {},
   "source": [
    "## Examine performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cea4972",
   "metadata": {},
   "outputs": [],
   "source": [
    "swt = spacy_word_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d126b07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>B-CARDINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           token         tag\n",
       "0      Thousands  B-CARDINAL\n",
       "1             of           O\n",
       "2  demonstrators           O\n",
       "3           have           O\n",
       "4        marched           O"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fcc3a2",
   "metadata": {},
   "source": [
    "### Make sure all tokens match\n",
    "\n",
    "Here we verify that the tokens from our training data match the tokens we created for the Spacy predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "baf7ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkWordVectors(word_true, word_cmp):\n",
    "    for i, tok in enumerate(word_cmp):\n",
    "        if tok != word_true.iloc[i]:\n",
    "            print(tok, word_true.iloc[i])\n",
    "            return 0\n",
    "            \n",
    "    return 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d446321",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert checkWordVectors(df['tidy_word'], swt['token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fd284c",
   "metadata": {},
   "source": [
    "### Remove 'I' and 'B' tags\n",
    "\n",
    "We want to get a preliminary look at the performance and not (at least not yet) worry about which token is used as the starting token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f8faaffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tag2'] = df['Tag'].apply(lambda tok: tok.replace('I-', ''))\n",
    "df['Tag2'] = df['Tag2'].apply(lambda tok: tok.replace('B-', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03f2ae4",
   "metadata": {},
   "source": [
    "### Convert Spacy tags\n",
    "\n",
    "Here we try and translate the Spacy tags to the same representation as our training data.\n",
    "\n",
    "PERSON:      People, including fictional.<br/>\n",
    "NORP:        Nationalities or religious or political groups.<br/>\n",
    "FAC:         Buildings, airports, highways, bridges, etc.<br/>\n",
    "ORG:         Companies, agencies, institutions, etc.<br/>\n",
    "GPE:         Countries, cities, states.<br/>\n",
    "LOC:         Non-GPE locations, mountain ranges, bodies of water.<br/>\n",
    "PRODUCT:     Objects, vehicles, foods, etc. (Not services.)<br/>\n",
    "EVENT:       Named hurricanes, battles, wars, sports events, etc.<br/>\n",
    "WORK_OF_ART: Titles of books, songs, etc.<br/>\n",
    "LAW:         Named documents made into laws.<br/>\n",
    "LANGUAGE:    Any named language.<br/>\n",
    "DATE:        Absolute or relative dates or periods.<br/>\n",
    "TIME:        Times smaller than a day.<br/>\n",
    "PERCENT:     Percentage, including ”%“.<br/>\n",
    "MONEY:       Monetary values, including unit.<br/>\n",
    "QUANTITY:    Measurements, as of weight or distance.<br/>\n",
    "ORDINAL:     “first”, “second”, etc.<br/>\n",
    "CARDINAL:    Numerals that do not fall under another type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "408a8cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'per', 'org', 'geo', 'tim', 'art', 'eve', 'gpe', 'nat']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = df['Tag'].value_counts()\n",
    "base_tags = [t.replace('I-', '') for t in tags.index if not t.startswith('B')]\n",
    "base_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b29ed049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeTags(swt, spacy2ref):\n",
    "    swt['tag2'] = swt['tag'].apply(lambda tok: tok.replace('I-', ''))\n",
    "    swt['tag2'] = swt['tag2'].apply(lambda tok: tok.replace('B-', ''))\n",
    "    for k in spacy2ref:\n",
    "        swt['tag2'] = swt['tag2'].apply(lambda tok: tok.replace(k, spacy2ref[k]))\n",
    "        \n",
    "    return swt\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3669d177",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy2ref = {'GPE': 'gpe', 'ORG': 'org', 'PERSON': 'per', 'DATE': 'tim',\n",
    "             'TIME': 'tim', 'EVENT': 'eve', 'LOC': 'geo', 'ORDINAL': 'O',\n",
    "             'CARDINAL': 'O', 'MONEY': 'O', 'PERCENT': 'O', 'GEO': 'geo', \n",
    "             'QUANTITY': 'O', 'FAC': 'geo', 'LAW': 'O', 'PRODUCT': 'O', \n",
    "             'WORK_OF_ART': 'art', 'LANGUAGE': 'O', 'NORP': 'gpe'}\n",
    "swt = normalizeTags(swt, spacy2ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ccf5c094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O      410297\n",
       "gpe     32429\n",
       "tim     21015\n",
       "org     17595\n",
       "per     14008\n",
       "geo      3199\n",
       "eve      1209\n",
       "art       248\n",
       "Name: tag2, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out how many observations we have for each Spacy tag\n",
    "swt['tag2'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb16442",
   "metadata": {},
   "source": [
    "### Check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "548d4c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMatches(df, swt):\n",
    "    \"\"\"\n",
    "    Create binary vector of size swt.shape[0] with a one\n",
    "    for every element where the tags match and a 0 otherwise.\n",
    "    \n",
    "    Also return a count of the number of misses and number of matches.\n",
    "    \"\"\"\n",
    "    match_idx = np.zeros(swt.shape[0])\n",
    "    match = 0\n",
    "    miss = 0\n",
    "    for i, tok in enumerate(swt):\n",
    "        if tok != df.iloc[i]:\n",
    "            miss += 1\n",
    "        else:\n",
    "            match += 1\n",
    "            match_idx[i] = 1\n",
    "    \n",
    "    print(f'correct: {100 * match/swt.shape[0]:.1f}, incorrect: {100 * miss/swt.shape[0]:.1f}')\n",
    "    return (match, miss, match_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "891bff4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 88.5, incorrect: 11.5\n"
     ]
    }
   ],
   "source": [
    "match, miss, match_idx = findMatches(df['Tag2'], swt['tag2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675b6abd",
   "metadata": {},
   "source": [
    "Here we see about 89% accuracy. However, this data is quite imbalanced, so we need to check and see if the success is just limited to prediction of the dominant class ('O')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "50d185ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into observations where the tags\n",
    "# match and observations that do not match\n",
    "def missMatchSplit(swt, match_idx):\n",
    "    cmp = swt.copy()\n",
    "    cmp['dftag'] = df['Tag2']\n",
    "    cmp_match = cmp[match_idx == 1]\n",
    "    cmp_miss = cmp[match_idx == 0]\n",
    "    \n",
    "    return cmp_miss, cmp_match\n",
    "\n",
    "def missMatchTable(cmp_match, cmp_miss):\n",
    "    return pd.DataFrame({'miss': cmp_miss['dftag'].value_counts(), 'match': cmp_match['dftag'].value_counts(), 'pct correct': cmp_match['dftag'].value_counts() / (cmp_match['dftag'].value_counts() + cmp_miss['dftag'].value_counts())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f2f2ee8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>miss</th>\n",
       "      <th>match</th>\n",
       "      <th>pct correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>18221</td>\n",
       "      <td>398529.0</td>\n",
       "      <td>0.956278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>art</th>\n",
       "      <td>342</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.065574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eve</th>\n",
       "      <td>156</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.551724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geo</th>\n",
       "      <td>21473</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>0.085009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpe</th>\n",
       "      <td>684</td>\n",
       "      <td>7803.0</td>\n",
       "      <td>0.919406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nat</th>\n",
       "      <td>142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>org</th>\n",
       "      <td>7605</td>\n",
       "      <td>11144.0</td>\n",
       "      <td>0.594378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per</th>\n",
       "      <td>7031</td>\n",
       "      <td>11081.0</td>\n",
       "      <td>0.611804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tim</th>\n",
       "      <td>2089</td>\n",
       "      <td>11489.0</td>\n",
       "      <td>0.846148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      miss     match  pct correct\n",
       "O    18221  398529.0     0.956278\n",
       "art    342      24.0     0.065574\n",
       "eve    156     192.0     0.551724\n",
       "geo  21473    1995.0     0.085009\n",
       "gpe    684    7803.0     0.919406\n",
       "nat    142       NaN          NaN\n",
       "org   7605   11144.0     0.594378\n",
       "per   7031   11081.0     0.611804\n",
       "tim   2089   11489.0     0.846148"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp_miss, cmp_match = missMatchSplit(swt[['token', 'tag2']], match_idx)\n",
    "missMatchTable(cmp_match, cmp_miss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768bf102",
   "metadata": {},
   "source": [
    "The above table shows that we have very poor performance with the `geo` tags. This could be due to differing definitions between the Spacy model and the training data. `gpe` seems to be the most likely category that could also be coded as `geo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "994ccb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missTags(cmp_miss, tag_true):\n",
    "    tag_counts = cmp_miss[cmp_miss['dftag'] == tag_true]['tag2'].value_counts()\n",
    "    samples = cmp_miss[cmp_miss['dftag'] == tag_true][['token', 'tag2']]\n",
    "    return tag_counts, samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78593c9e",
   "metadata": {},
   "source": [
    "As we suspect, most of the \"incorrect\" 'geo' tags are marked as 'gpe'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dad6cb99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gpe    17631\n",
       "O       1422\n",
       "org     1397\n",
       "per      884\n",
       "eve       69\n",
       "tim       47\n",
       "art       23\n",
       "Name: tag2, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_counts, mistakes = missTags(cmp_miss, 'geo')\n",
    "tag_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb7dbc3",
   "metadata": {},
   "source": [
    "The table below shows that the vast majority of the tokens \"mislabeled\" as 'gpe', appear quite reasonably labeled as 'gpe'. It is possible that one of the models is using context better than the other.\n",
    "\n",
    "The top 20 by count account for more than 55% of the \"mislabeled\" 'geo' tags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "45c65fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8773"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistakes.value_counts().iloc[0:20].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "de9d6c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "token        tag2\n",
       "US           gpe     1627\n",
       "Iraq         gpe      884\n",
       "United       gpe      656\n",
       "States       gpe      655\n",
       "Iran         gpe      552\n",
       "Afghanistan  gpe      506\n",
       "Israel       gpe      469\n",
       "China        gpe      439\n",
       "Baghdad      gpe      398\n",
       "Pakistan     gpe      377\n",
       "Russia       gpe      305\n",
       "Gaza         gpe      254\n",
       "Korea        gpe      250\n",
       "Washington   gpe      238\n",
       "India        gpe      234\n",
       "South        gpe      198\n",
       "North        gpe      195\n",
       "New          gpe      188\n",
       "UN           org      176\n",
       "Venezuela    gpe      172\n",
       "dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistakes.value_counts().iloc[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "87f2fd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0cff9b59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jason/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.97      0.96      0.96    416750\n",
      "         art       0.10      0.07      0.08       366\n",
      "         eve       0.16      0.55      0.25       348\n",
      "         geo       0.62      0.09      0.15     23468\n",
      "         gpe       0.24      0.92      0.38      8487\n",
      "         nat       0.00      0.00      0.00       142\n",
      "         org       0.63      0.59      0.61     18749\n",
      "         per       0.79      0.61      0.69     18112\n",
      "         tim       0.55      0.85      0.66     13578\n",
      "\n",
      "    accuracy                           0.88    500000\n",
      "   macro avg       0.45      0.51      0.42    500000\n",
      "weighted avg       0.91      0.88      0.88    500000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df['Tag2'].iloc[:500000], swt['tag2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c44f287",
   "metadata": {},
   "source": [
    "### Change tag to tag translation\n",
    "\n",
    "Let's try defining the Spacy assigned `gpe` tags as `geo` tags and see how the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "87fbf3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy2ref = {'GPE': 'geo', 'ORG': 'org', 'PERSON': 'per', 'DATE': 'tim',\n",
    "             'TIME': 'tim', 'EVENT': 'eve', 'LOC': 'geo', 'ORDINAL': 'O',\n",
    "             'CARDINAL': 'O', 'MONEY': 'O', 'PERCENT': 'O', 'GEO': 'geo', \n",
    "             'QUANTITY': 'O', 'FAC': 'geo', 'LAW': 'O', 'PRODUCT': 'O', \n",
    "             'WORK_OF_ART': 'art', 'LANGUAGE': 'O', 'NORP': 'gpe'}\n",
    "swt = normalizeTags(swt, spacy2ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2a11d408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jason/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.97      0.96      0.96    416750\n",
      "         art       0.10      0.07      0.08       366\n",
      "         eve       0.16      0.55      0.25       348\n",
      "         geo       0.76      0.81      0.79     23468\n",
      "         gpe       0.68      0.84      0.75      8487\n",
      "         nat       0.00      0.00      0.00       142\n",
      "         org       0.63      0.59      0.61     18749\n",
      "         per       0.79      0.61      0.69     18112\n",
      "         tim       0.55      0.85      0.66     13578\n",
      "\n",
      "    accuracy                           0.92    500000\n",
      "   macro avg       0.52      0.59      0.53    500000\n",
      "weighted avg       0.92      0.92      0.92    500000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df['Tag2'].iloc[:500000], swt['tag2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e68fa2",
   "metadata": {},
   "source": [
    "Switching the Spacy `gpe` tags to `geo` has greatly increased the f1-score for both `geo` and `gpe`:\n",
    "\n",
    "Before `gpe` --> `geo`:\n",
    "\n",
    "```\n",
    "     precision    recall  f1-score\n",
    "geo       0.62      0.09      0.15\n",
    "gpe       0.24      0.92      0.38\n",
    "```\n",
    "\n",
    "after\n",
    "\n",
    "\n",
    "```\n",
    " geo       0.76      0.81      0.79\n",
    " gpe       0.68      0.84      0.75\n",
    " ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
