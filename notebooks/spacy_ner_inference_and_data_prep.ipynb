{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1351,
   "id": "df7ff5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1352,
   "id": "5182eaed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 4)"
      ]
     },
     "execution_count": 1352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/'\n",
    "df = pd.read_csv(data_path + 'ner_dataset.zip', encoding=\"latin1\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1353,
   "id": "d4ffc9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 1353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0d42ec",
   "metadata": {},
   "source": [
    "## Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1354,
   "id": "b0b21be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep all numbers, all letters and hyphens\n",
    "df['tidy_word'] = df['Word'].apply(lambda x: re.sub(\"[^a-zA-Z0-9\\-]\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "id": "d17e36a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove observations that are now empty\n",
    "df = df[df['tidy_word'] != '']\n",
    "\n",
    "# Hyphenated words are kept as a single token\n",
    "# in this dataset. Remove observations that\n",
    "# are a between-word dash. This causes problems\n",
    "# with the algorithm\n",
    "df = df[df['tidy_word'] != '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1356,
   "id": "482b18d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later steps require a consecutive index\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485d6f33",
   "metadata": {},
   "source": [
    "### Create Sentence Form of Text\n",
    "\n",
    "We create a new Series where each row is a list with the contents of a sentence. We do this so that it can be more easily sent to Spacy NER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1357,
   "id": "794108e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toSentenceForm(df, var):\n",
    "    \"\"\"\n",
    "    From a Series:\n",
    "    \n",
    "        Sentence  #      var\n",
    "        -----------  -------\n",
    "        Sentence: 1     Mary\n",
    "                NaN      had\n",
    "                NaN        a\n",
    "                NaN   little\n",
    "                NaN     lamb\n",
    "                NaN        .\n",
    "        Sentence: 2       He\n",
    "                NaN followed\n",
    "                NaN      her\n",
    "                \n",
    "    to a list of lists of strings by sentence:\n",
    "    \n",
    "        [['Mary', 'had', 'a', 'little', 'lamb' '.'],\n",
    "         ['He', 'followed', 'her', ...]]\n",
    "                                \n",
    "    \"\"\"\n",
    "    sent_out = []\n",
    "\n",
    "    # Find the index of each sentence start\n",
    "    idx = df['Sentence #'].isna()\n",
    "    sent_breaks = df[idx == False].index\n",
    "    \n",
    "    \n",
    "    for i in range(len(sent_breaks)-1):\n",
    "        \n",
    "        # Create a list containing all strings\n",
    "        # from the current sentence\n",
    "        out = []\n",
    "        for j in range(sent_breaks[i], sent_breaks[i+1]):\n",
    "            out.append(df[var].iloc[j])\n",
    "        \n",
    "        # Append ith sentence list to the\n",
    "        # list of all sentences\n",
    "        sent_out.append(out)\n",
    "\n",
    "    return sent_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "id": "8dac69f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = toSentenceForm(df, 'tidy_word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1359,
   "id": "6869a95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = toSentenceForm(df, 'Tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1360,
   "id": "d2c3512b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "se = pd.DataFrame({'sentence_list': sentences, 'tags': tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1361,
   "id": "e983d3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_list</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
       "      <td>[O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Families, of, soldiers, killed, in, the, conf...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[They, marched, from, the, Houses, of, Parliam...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-geo, I-geo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Police, put, the, number, of, marchers, at, 1...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The, protest, comes, on, the, eve, of, the, a...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-geo, O, O,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       sentence_list  \\\n",
       "0  [Thousands, of, demonstrators, have, marched, ...   \n",
       "1  [Families, of, soldiers, killed, in, the, conf...   \n",
       "2  [They, marched, from, the, Houses, of, Parliam...   \n",
       "3  [Police, put, the, number, of, marchers, at, 1...   \n",
       "4  [The, protest, comes, on, the, eve, of, the, a...   \n",
       "\n",
       "                                                tags  \n",
       "0  [O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...  \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2    [O, O, O, O, O, O, O, O, O, O, O, B-geo, I-geo]  \n",
       "3         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, B-geo, O, O,...  "
      ]
     },
     "execution_count": 1361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1362,
   "id": "d2e34aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "se.to_csv('../data/ner_sentences.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecaacec",
   "metadata": {},
   "source": [
    "### Perform NER\n",
    "\n",
    "Spacy will automatically perform NER when we create a Doc object from a sentence.\n",
    "\n",
    "Iterate over all words and tags in the Doc object and create lists of tokens and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1363,
   "id": "67f2df24",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1389,
   "id": "efcb4345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0:\t47839 (0.00%)\n",
      "      2500:\t47839 (5.23%)\n",
      "      5000:\t47839 (10.45%)\n",
      "      7500:\t47839 (15.68%)\n",
      "     10000:\t47839 (20.90%)\n",
      "     12500:\t47839 (26.13%)\n",
      "     15000:\t47839 (31.36%)\n",
      "     17500:\t47839 (36.58%)\n",
      "     20000:\t47839 (41.81%)\n",
      "     22500:\t47839 (47.03%)\n",
      "     25000:\t47839 (52.26%)\n",
      "     27500:\t47839 (57.48%)\n",
      "     30000:\t47839 (62.71%)\n",
      "     32500:\t47839 (67.94%)\n",
      "     35000:\t47839 (73.16%)\n",
      "     37500:\t47839 (78.39%)\n",
      "     40000:\t47839 (83.61%)\n",
      "     42500:\t47839 (88.84%)\n",
      "     45000:\t47839 (94.07%)\n",
      "     47500:\t47839 (99.29%)\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "spacy_tags = []\n",
    "doc = nlp(fs)\n",
    "ctr = 0\n",
    "\n",
    "# number of iterations between progress report\n",
    "report_freq = 2500\n",
    "\n",
    "for row, sentence in enumerate(se['sentence_list']):\n",
    "    doc = nlp(' '.join(sentence))\n",
    "\n",
    "    # Print progress report\n",
    "    if row == int(row / report_freq) * report_freq:\n",
    "        print(f'{row:10.9g}:\\t{se.shape[0]} ({100*row/se.shape[0]:.2f}%)')\n",
    "    \n",
    "    # Iterate over tokens in doc\n",
    "    # and create lists of tokens and tags\n",
    "    for i, t in enumerate(doc):\n",
    "        words.append(t)\n",
    "        if t.ent_iob_ == 'O':\n",
    "            spacy_tags.append('O')\n",
    "        else:\n",
    "            spacy_tags.append(t.ent_iob_+'-'+t.ent_type_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "id": "3745dfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spacy = pd.DataFrame({'Words': words, 'Tags': spacy_tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1391,
   "id": "345e4f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(981669, 2)"
      ]
     },
     "execution_count": 1391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spacy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1392,
   "id": "d5ce0817",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spacy.to_csv('../data/ner_spacy_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1393,
   "id": "0337fe5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>B-CARDINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>through</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>London</td>\n",
       "      <td>B-GPE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Words        Tags\n",
       "0      Thousands  B-CARDINAL\n",
       "1             of           O\n",
       "2  demonstrators           O\n",
       "3           have           O\n",
       "4        marched           O\n",
       "5        through           O\n",
       "6         London       B-GPE"
      ]
     },
     "execution_count": 1393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spacy.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "id": "df75e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def containsHyphen(s):\n",
    "    return len(s) > 1 and (s.find('-') > -1)\n",
    "\n",
    "def findHyphenatedWord(s, s_list, idx):\n",
    "    return s + s_list[idx+1] + s_list[idx+2]\n",
    "\n",
    "def findAdditionalHyphens(s, s_list, idx, inc):\n",
    "        finished = 1\n",
    "        idx += inc\n",
    "        if idx < len(s_list) and s_list[idx] == '-':\n",
    "            s = findHyphenatedWord(s, s_list, idx-1)\n",
    "            finished = 0\n",
    "            return (idx, s, finished)\n",
    "        else:\n",
    "            return (idx, s, finished)\n",
    "\n",
    "def findHyphenatedWords(s_list, idx):\n",
    "    s = s_list[idx]\n",
    "    s = findHyphenatedWord(s, s_list, idx)\n",
    "    \n",
    "    finished = 0  # have we found all connected hyphens?\n",
    "    increment = 3 # the first additional hyphen is further than\n",
    "                  # subsequent ones, because the original 'idx'\n",
    "                  # is pointing at a word, but the after calling\n",
    "                  # findAdditionalHyphens() 'idx' will point at a\n",
    "                  # hyphen after the word\n",
    "                  \n",
    "    \n",
    "    while finished == 0:\n",
    "        idx, s, finished = findAdditionalHyphens(s, s_list, idx, increment)\n",
    "        increment = 2\n",
    "                \n",
    "\n",
    "    return (idx, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1395,
   "id": "c9f15dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [ 'apple', 'apple-jacks', 'chocolate', 'coco-puffs-again', \n",
    "     'old-mcdonald-had-a-farm']\n",
    "b = [ 'apple', 'apple', '-', 'jacks', 'chocolate', 'coco', \n",
    "     '-', 'puffs', '-', 'again', 'old', '-', 'mcdonald', '-', 'had', \n",
    "     '-', 'a', '-', 'farm']\n",
    "\n",
    "def test_findHyphenatedWords(a, b):\n",
    "    c = []\n",
    "    i = 0\n",
    "    for ai in (a):\n",
    "        if containsHyphen(ai):\n",
    "            i, ss = findHyphenatedWords(b, i)\n",
    "            c.append(ss)\n",
    "        else:\n",
    "            c.append(b[i])\n",
    "            i += 1\n",
    "\n",
    "    c_cmp = ['apple',\n",
    "             'apple-jacks',\n",
    "             'chocolate',\n",
    "             'coco-puffs-again',\n",
    "             'old-mcdonald-had-a-farm']\n",
    "\n",
    "    return c == c_cmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1396,
   "id": "165c68df",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert test_findHyphenatedWords(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec29f58",
   "metadata": {},
   "source": [
    "### Align tokens and tags\n",
    "\n",
    "Spacy breaks up some words differently than our dataset. Below, we create a list of the tokens from our original dataset and their Spacy tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1401,
   "id": "dcea2121",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "i: 168074 j: 171909 c: ['wont'] word: \"wont\", sp_word[0]: \"[wo, nt]\"\n",
      "done\n",
      "i: 189964 j: 194298 c: ['wed'] word: \"wed\", sp_word[0]: \"[we, d]\"\n"
     ]
    }
   ],
   "source": [
    "c = []\n",
    "s_tags = []\n",
    "i = 0\n",
    "j = 0\n",
    "supress_til = 1780\n",
    "for word in df['tidy_word']:\n",
    "    if containsHyphen(word):\n",
    "        # grabbing a bunch of words in case we have to search\n",
    "        # and grab more tokens from hyphenated words\n",
    "        sp_word = [w.text for w in df_spacy['Words'].iloc[j:j+9]]\n",
    "        if sp_word[0] == word:\n",
    "            sp_tag_tmp = df_spacy['Tags'].iloc[j]\n",
    "            s_tags.append(sp_tag_tmp)\n",
    "            c.append(word)\n",
    "            \n",
    "            j += 1\n",
    "        else:\n",
    "            k = 0\n",
    "            k, ss = findHyphenatedWords(sp_word, k)\n",
    "            \n",
    "            sp_tag_tmp = df_spacy['Tags'].iloc[j]\n",
    "            s_tags.append(sp_tag_tmp)\n",
    "            \n",
    "            j += k\n",
    "            \n",
    "            c.append(ss)\n",
    "    else:\n",
    "        next_sp_word_ = df_spacy[\"Words\"].iloc[j]\n",
    "        if len(word) > 1 and word.endswith('.'):\n",
    "            next_sp_word = df_spacy[\"Words\"].iloc[j+1]\n",
    "            if next_sp_word.text == '.':\n",
    "                j += 1\n",
    "                \n",
    "        sp_tag_tmp = df_spacy['Tags'].iloc[j]\n",
    "        s_tags.append(sp_tag_tmp)\n",
    "        c.append(next_sp_word_.text)\n",
    "        j += 1\n",
    "        \n",
    "    i += 1\n",
    "    if len(c) == 500000:\n",
    "        break\n",
    "        \n",
    "    if c[-1] != word:\n",
    "        # try and take care of times where Spacy splits 'wont', 'wed'\n",
    "        tmpa = df_spacy[\"Words\"].iloc[j]\n",
    "        tmp = c[-1] + tmpa.text\n",
    "        if tmp == word:\n",
    "            c[-1] = tmp\n",
    "            \n",
    "        j += 1\n",
    "            \n",
    "        print('done')\n",
    "        print(f'i: {i} j: {j} c: {c[-1:]} word: \"{word}\", sp_word[0]: \"{list(df_spacy[\"Words\"].iloc[j-2:j])}\"')\n",
    "#         break\n",
    "    last_word = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1402,
   "id": "7db9c262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-CARDINAL' 'B-DATE' 'B-EVENT' 'B-FAC' 'B-GPE' 'B-LANGUAGE' 'B-LAW'\n",
      " 'B-LOC' 'B-MONEY' 'B-NORP' 'B-ORDINAL' 'B-ORG' 'B-PERCENT' 'B-PERSON'\n",
      " 'B-PRODUCT' 'B-QUANTITY' 'B-TIME' 'B-WORK_OF_ART' 'I-CARDINAL' 'I-DATE'\n",
      " 'I-EVENT' 'I-FAC' 'I-GPE' 'I-LAW' 'I-LOC' 'I-MONEY' 'I-NORP' 'I-ORG'\n",
      " 'I-PERCENT' 'I-PERSON' 'I-PRODUCT' 'I-QUANTITY' 'I-TIME' 'I-WORK_OF_ART'\n",
      " 'O']\n"
     ]
    }
   ],
   "source": [
    "all_spacy_tags = np.unique(s_tags)\n",
    "print(all_spacy_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1403,
   "id": "1c2e073c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>B-CARDINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           token         tag\n",
       "0      Thousands  B-CARDINAL\n",
       "1             of           O\n",
       "2  demonstrators           O\n",
       "3           have           O\n",
       "4        marched           O"
      ]
     },
     "execution_count": 1403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_word_tag = pd.DataFrame({'token': c, 'tag': s_tags})\n",
    "spacy_word_tag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1404,
   "id": "bd0bc999",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_word_tag.to_csv('../data/ner_spacy_aligned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91572c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
